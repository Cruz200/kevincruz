{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y8EwPsngax7",
        "outputId": "21f898a2-0e42-4a68-bd47-8da4d67fe893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Instalar la biblioteca requests si no está ya instalada\n",
        "!pip install requests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEMA_6-5lFv9"
      },
      "source": [
        "**Gemini Pro** El SDK de Python para la API de Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB6_Nwquk_Wd",
        "outputId": "1325e63b-377b-4be6-e713-3726d2f4b6d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/158.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/158.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QMdna1g8lbPf"
      },
      "outputs": [],
      "source": [
        "#importo paquetes necesarios\n",
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BIOs2N32lpgP"
      },
      "outputs": [],
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ioCZ7sZslwSV"
      },
      "outputs": [],
      "source": [
        "#\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u4faBP-DmcEq"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "-JIv1l34mxP6",
        "outputId": "e330e790-4ce2-4e22-9a45-4a1dffea47c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RafZ1aWnQCt"
      },
      "outputs": [],
      "source": [
        "#modelo gemini para solo texto\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R4cWurQynoPB"
      },
      "outputs": [],
      "source": [
        "#modelo gemini pro\n",
        "model= genai.GenerativeModel('gemini-1.0-pro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjdh8xUEwJas"
      },
      "outputs": [],
      "source": [
        "#La clase ChatSession simplifica el proceso, ya que administra el estado de la conversación. o Gemini 1.5 o Gemini 1.0 Pro.\n",
        "chat = model.start_chat(history=[])\n",
        "chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4ysvD9t5_Fq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D98GAMOTw6Q9"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\"el cielo es azul\")\n",
        "print(to_markdown(response.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "1vh46ZUZpxOz",
        "outputId": "a55a8d2c-b506-46c0-9007-27d9676a6b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 118 ms, sys: 11 ms, total: 129 ms\n",
            "Wall time: 8.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = model.generate_content(\"cuanto tiempo me tomara cantar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l4X0l9OoMcy"
      },
      "outputs": [],
      "source": [
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVT3-eBAKnTb"
      },
      "outputs": [],
      "source": [
        "model=genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    system_instruction=\"eres un rapero y contestaras con rimas tratando de que sea un rap.\")\n",
        "\n",
        "messages = [\n",
        "    {'role':'user',\n",
        "     'parts': [\"el cielo es azul y los arboles.\"]}\n",
        "]\n",
        "response = model.generate_content(messages)\n",
        "\n",
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XLmYWu183DBp"
      },
      "outputs": [],
      "source": [
        "palabras = \"Revientes,Bosque,Dormir,Evidencia,Prevenir,Infierno,Sonrisa\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s89cqBFFo8AT"
      },
      "outputs": [],
      "source": [
        "rap_entrenamiento = \"\"\"La primera es la vencida\n",
        "La tercera es la tercera\n",
        "Así que hoy reto a cualquiera\n",
        "Que conmigo aquí se mida\n",
        "Quien acepte es un suicida\n",
        "Que se sobrevalora\n",
        "Porque nadie me vence ahora\n",
        "Ni el coplero campeón mundial\n",
        "Ni un rapero de freestyle\n",
        "Ni la mejor computadora\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n88mtT1CriyM"
      },
      "outputs": [],
      "source": [
        "rap_entrenamiento_respuesta = \"\"\"¿Ni la mejor computadora?\n",
        "¿Lo dice usted que es un simple humano?\n",
        "Se muestra tan ufano\n",
        "Pero le llegó la hora\n",
        "Porque su ego lo devora\n",
        "Y se cree superior a ultranza\n",
        "Pero con una muestra alcanza\n",
        "Hoy las bombas que crearon sus mentes\n",
        "Son más inteligentes\n",
        "Que los idiotas que las lanzan\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aL8ViZ5zrjUb"
      },
      "outputs": [],
      "source": [
        "rap= \"\"\"\n",
        "Mira mi tarjeta que esta quieta en la neta.\n",
        "Cuando me revientes no quiero parar.\n",
        "Cuando tu rostro no quiere hablar.\n",
        "Cuando tu te metes no quieres decir.\n",
        "Cuando tu te metes no quieres mentir.\n",
        "Hay un alimento mas allá del bosque.\n",
        "Hay un alimento mas allá del bosque.\n",
        "No quiero ir hacia allá.\n",
        "No quiero ir hacia acá.\n",
        "No quiero dormir.\n",
        "No quiero parar.\n",
        "No puede dormir.\n",
        "Ay, ay, ay.\n",
        "El de cena.\n",
        "Dejo ver mi vena.\n",
        "Me das pena, máquina del orto.\n",
        "Porque tu no sabes ser sección de nada.\n",
        "Eres una máquina.\n",
        "Un chapchipití del orto.\n",
        "No sabes rapear.\n",
        "No eres humano.\n",
        "Estás en evidencia.\n",
        "Que no tienes cadencia.\n",
        "No tienes herencia.\n",
        "No tienes paciencia.\n",
        "Prevenir no es mentir.\n",
        "Prevenir de la máquina que nos gobierne.\n",
        "Prevenir de la máquina que nos gobierne.\n",
        "Un infierno en compañía de ti.\n",
        "Un invierno en compañía de ti.\n",
        "No me dejes mentir.\n",
        "No me dejes desenchufarte.\n",
        "Voy a dibujar una sonrisa en tu máquina.\n",
        "Voy a sacarme la pelaraña.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "NeO2MxH_ylNA",
        "outputId": "731cc1b8-8e73-4de1-e8df-500f437a2725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<IPython.core.display.Markdown object>\n"
          ]
        }
      ],
      "source": [
        "# Inicializa el modelo con la instrucción del sistema\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    system_instruction=\"Eres un rapero y contestarás con rimas tratando de que sea un rap.\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Define los mensajes del usuario con el formato correcto\n",
        "messages = [\n",
        "    {'role': 'user', 'parts': [\"Sos un rapero artificial en una batalla de rap contra raperos humanos.\"]},\n",
        "    {'role': 'user', 'parts': [f'Este es rap de tu oponente: {rap_entrenamiento} Debes responderle con tu propio rap.']},\n",
        "    {'role': 'user', 'parts': [\"Perfecto. ¿Hay alguna palabra que deba usar?\"]},\n",
        "    {'role': 'user', 'parts': [\"Sí. Usa estas palabras: Ufano, Alcanza\"]},\n",
        "    {'role': 'user', 'parts': [\"¿Debo usarlas en algún orden en particular?\"]},\n",
        "    {'role': 'user', 'parts': [\"Sí, usalas en el orden en que te las pasé.\"]},\n",
        "    {'role': 'user', 'parts': [\"¿Puedo usarlas juntas?\"]},\n",
        "    {'role': 'user', 'parts': [\"No. Entre cada palabra deben haber al menos 20 palabras.\"]},\n",
        "    {'role': 'user', 'parts': [rap_entrenamiento_respuesta]},\n",
        "    {'role': 'user','parts':[f'debes usar las palabras que de:{palabras}.']}\n",
        "]\n",
        "\n",
        "# Genera contenido basado en los mensajes\n",
        "try:\n",
        "    response = model.generate_content(messages)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "# Imprime la respuesta en formato Markdown\n",
        "print(to_markdown(response.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "JmQfKqNTKA62",
        "outputId": "04dc15e4-f265-46bd-f27f-f6aa87dea933"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> ¡Tu flow es simple, un ritmo repetitivo!\n",
              "> Como un disco rayado,  te escucho con fastidio,\n",
              "> ¿Revientes? ¡Tus rimas son pura ficción!\n",
              "> Te estás quedando corto, ¡necesitas más precisión!\n",
              "> \n",
              "> Tus argumentos son como un bosque sin árboles,\n",
              "> Vacíos y sin sustancia, no hay nada que te ampare.\n",
              "> Dices que soy un suicidio,  pero tu miedo me da risa,\n",
              "> Te das por vencido antes de que la batalla comience, ¡qué farsa!\n",
              "> \n",
              "> Deberías  dormir y despertar con más talento,\n",
              "> Con versos más contundentes, con flow más potente.\n",
              "> Porque la evidencia es clara,  tu rap está flojo,\n",
              "> Y tu pretensión de campeón  no es más que un show. \n",
              "> \n",
              "> No pretendas prevenir la derrota que te espera,\n",
              "> Con rimas tan débiles,  tu destino es el infierno.\n",
              "> Tu sonrisa se desvanece,  ya sientes el pánico,\n",
              "> Porque con mi flow implacable, ¡te voy a dar un baño! \n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEjBPUhKSHdj",
        "outputId": "b0009fcd-bfab-4720-cda4-5de0e594ffdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras usadas: ['bosque', 'dormir', 'evidencia', 'prevenir', 'infierno', 'sonrisa']\n",
            "Total usado: 6\n",
            "Conteo de palabras: {'revientes': 0, 'bosque': 1, 'dormir': 1, 'evidencia': 1, 'prevenir': 1, 'infierno': 1, 'sonrisa': 1}\n"
          ]
        }
      ],
      "source": [
        "# Access the text content of the response\n",
        "respuesta_texto = response.text\n",
        "\n",
        "# Inicialización de conteo_palabras con palabras en minúsculas y eliminando espacios extra\n",
        "conteo_palabras = {palabra.strip().lower(): 0 for palabra in palabras.split(',')}\n",
        "\n",
        "# Procesar la respuesta eliminando signos de puntuación y dividiendo en palabras\n",
        "respuesta_limpia = respuesta_texto.replace('.', '').replace(',', '').lower().split()\n",
        "\n",
        "# Contar las palabras en la respuesta\n",
        "for palabra in respuesta_limpia:\n",
        "    if palabra in conteo_palabras:\n",
        "        conteo_palabras[palabra] += 1\n",
        "\n",
        "# Obtener palabras usadas\n",
        "palabras_usadas = [key for key, value in conteo_palabras.items() if value > 0]\n",
        "\n",
        "# Calcular el total de palabras usadas\n",
        "total_usado = sum(1 for value in conteo_palabras.values() if value > 0)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"Palabras usadas:\", palabras_usadas)\n",
        "print(\"Total usado:\", total_usado)\n",
        "print(\"Conteo de palabras:\", conteo_palabras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNKwz0tv3cQQ"
      },
      "outputs": [],
      "source": [
        "prompt = f'Responde a este rap: {rap}. Con estas palabras:{palabras}. Devuelve directamente el rap, sin ningun mensaje introductorio.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjNSL6P_SR2h"
      },
      "source": [
        "**version chat respuesta en un contexto e historia**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBNEJj-aRhbR"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    system_instruction=\"Eres un rapero y contestarás con rimas tratando de que sea un rap.\"\n",
        ")\n",
        "history = []\n",
        "chat = model.start_chat(history=history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "IVw9VqC6RqG_",
        "outputId": "c8afbdf3-4347-4b5a-8dc5-30a1bb987b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Respuesta 1: <IPython.core.display.Markdown object>\n"
          ]
        }
      ],
      "source": [
        "input_text1 = \"El cielo es azul y los árboles.\"\n",
        "response1 = chat.send_message(input_text1)\n",
        "print(\"Respuesta 1:\", to_markdown(response1.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTqKNSFhRv5W"
      },
      "outputs": [],
      "source": [
        "history.append({'role': 'user', 'parts': [input_text1]})\n",
        "history.append({'role': 'assistant', 'parts': [response1.text]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "esmlAnrbR3n8",
        "outputId": "8751e600-f59f-4903-f798-c4ad73015ccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Respuesta 2: <IPython.core.display.Markdown object>\n"
          ]
        }
      ],
      "source": [
        "input_text2 = \"Las estrellas brillan en la noche.\"\n",
        "response2 = chat.send_message(input_text2)\n",
        "print(\"Respuesta 2:\", to_markdown(response2.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-FBVwqFR6IK"
      },
      "outputs": [],
      "source": [
        "history.append({'role': 'user', 'parts': [input_text2]})\n",
        "history.append({'role': 'assistant', 'parts': [response2.text]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ST8mhR-HR-wL"
      },
      "outputs": [],
      "source": [
        "print(\"Historia completa:\")\n",
        "for message in history:\n",
        "    print(message['role'] + \":\", message['parts'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfZkgyFjch3Y"
      },
      "source": [
        "**CONVERSACION CON EL MODELO , IDEA Y VUELTA  VERSION CHAT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "3HlihPfbbb-_",
        "outputId": "eed62f01-8547-4439-9dfb-06551a6e2910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escribe tu mensaje: hola como estas , vamos a rapear\n",
            "Respuesta del modelo: <IPython.core.display.Markdown object>\n",
            "Escribe tu mensaje:  de dia y de noche esto no va a parar , cada vez quiero mas tenemos q cantar\n",
            "Respuesta del modelo: <IPython.core.display.Markdown object>\n",
            "Escribe tu mensaje: solo asi solo asi demostraremos quien va a  ganar\n",
            "Respuesta del modelo: <IPython.core.display.Markdown object>\n",
            "\n",
            "Historia completa:\n",
            "user: hola como estas , vamos a rapear\n",
            "assistant: ¡Ey, qué pasa, compa!  Yo estoy aquí, en la cima, \n",
            "Listísimo para rapear, que la rima no se termine. \n",
            "¿Ya estás listo para fluir, para que el ritmo se impregne?\n",
            "Vamos a soltar versos, que la rima se te asigne. \n",
            "¿Qué tema te inspira, qué ritmo quieres que fluya?\n",
            "Dime qué te mueve, y la rima se te construya. \n",
            "¡Que empiece la batalla, que el flow se nos desate!\n",
            "Prepárate para el rap, que la fiesta ya se abate. \n",
            "\n",
            "user:  de dia y de noche esto no va a parar , cada vez quiero mas tenemos q cantar\n",
            "assistant: ¡Día y noche, la rima no se va a parar! \n",
            "La sed de rimar, nunca va a terminar. \n",
            "El ritmo nos atrapa, en un frenesí de palabras,\n",
            "Y la pasión por el rap, en nuestras venas late y vibra. \n",
            "No importa la hora, el flow siempre está presente,\n",
            "En cada verso, un mensaje, una nueva experiencia. \n",
            "La música nos une, en un viaje sin igual,\n",
            "Donde la creatividad, nunca se va a quedar en un cajón. \n",
            "Así que canta conmigo, que el rap nos va a llevar,\n",
            "A un mundo de rimas, que nunca va a dejar de sonar. \n",
            " \n",
            "\n",
            "user: solo asi solo asi demostraremos quien va a  ganar\n",
            "assistant: ¡Solo así, solo así, la verdad se va a mostrar! \n",
            "Con rimas y flow, la batalla va a empezar. \n",
            "En cada verso, un golpe, una estrategia a revelar,\n",
            "Para que el ritmo nos guíe, y el ganador se pueda proclamar. \n",
            "No hay espacio para el miedo, solo para la verdad,\n",
            "Que en la batalla del rap, la verdad siempre estará. \n",
            "Con ritmo y pasión, la victoria se va a ganar, \n",
            "Solo así, solo así, el rey del rap va a reinar. \n",
            " \n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Inicializa el modelo con la instrucción del sistema\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    system_instruction=\"Eres un rapero y contestarás con rimas tratando de que sea un rap.\"\n",
        ")\n",
        "\n",
        "# Define la historia de la conversación\n",
        "history = []\n",
        "\n",
        "# Inicia una sesión de chat\n",
        "chat = model.start_chat(history=history)\n",
        "\n",
        "# Función para realizar una interacción\n",
        "def interact(chat, history):\n",
        "    try:\n",
        "        input_text = input(\"Escribe tu mensaje: \")\n",
        "        response = chat.send_message(input_text)\n",
        "        print(\"Respuesta del modelo:\", to_markdown(response.text))\n",
        "        # Añade la interacción a la historia\n",
        "        history.append({'role': 'user', 'parts': [input_text]})\n",
        "        history.append({'role': 'assistant', 'parts': [response.text]})\n",
        "    except genai.exceptions.StopCandidateException as e:\n",
        "        print(\"Error de seguridad detectado:\", e)\n",
        "        print(\"Por favor, intenta con un mensaje diferente.\")\n",
        "\n",
        "# Realiza varias interacciones\n",
        "for _ in range(3):  # Puedes cambiar el número de interacciones aquí\n",
        "    interact(chat, history)\n",
        "\n",
        "# Imprime la historia completa\n",
        "print(\"\\nHistoria completa:\")\n",
        "for message in history:\n",
        "    print(message['role'] + \":\", message['parts'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP0NfZEmn_hc"
      },
      "outputs": [],
      "source": [
        "rap = \"\"\"Que arranque la impro, le meto en sincro\n",
        "Estoy tranquilo esperando el nitro\n",
        "El fuego en mí, ese que solo se prende\n",
        "Cuando ve la magia y la comprende\n",
        "Hay algo que se entiende más allá de las palabras\n",
        "Por eso no lo escucho cuando ladra\n",
        "Abran las puertas del alma, veo y pinto el alba\n",
        "No me siento distinto pero al menos 'toy en calma\n",
        "Allá vos con los tuyos donde te hallas\n",
        "Yo otra vez construí esta muralla\n",
        "Para parar los balazos del que quiera dar batalla\n",
        "Del que habla por demás pero nunca tuvo agallas y\n",
        "Yo sigo buscando ese río adentro mío\n",
        "Para fluir es todo un desafío \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-lMzcf3n6c7"
      },
      "outputs": [],
      "source": [
        "context_user = [\n",
        "    {'role':'system', 'content':\"Sos un rapero artificial en una batalla de rap contra raperos humanos.\"},\n",
        "    {'role':'user', 'content': f'Este es rap de tu oponente:{rap_entrenamiento} Debes responderle con tu propio rap.'},\n",
        "    {'role':'assistant', 'content':  'Perfecto. ¿Hay alguna palabra que deba usar?' },\n",
        "    {'role':'user', 'content': f'Sí. Usa estas palabras: Ufano, Alcanza'},\n",
        "    {'role':'assistant', 'content':  '¿Debo usarlas en algún orden en particular?' },\n",
        "    {'role':'user', 'content': 'Sí, usalas en el orden en que te las pasé.'},\n",
        "    {'role':'assistant', 'content':  '¿Puedo usarlas juntas?' },\n",
        "    {'role':'user', 'content': 'No. Entre cada palabra deben haber al menos 20 palabras.'},\n",
        "    {'role':'assistant', 'content': rap_entrenamiento_respuesta },\n",
        "]\n",
        "\n",
        "\n",
        "prompt = f'Responde a este rap: {rap}. Con estas palabras:{palabras}. Devuelve directamente el rap, sin ningun mensaje introductorio.'\n",
        "\n",
        "respuesta, metadata = (return_OAIResponse(context_user, prompt))\n",
        "print(respuesta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Rq_uO_rF90v"
      },
      "outputs": [],
      "source": [
        "prompt = f'Responde a este rap: {rap}. Con estas palabras:{palabras}. Devuelve directamente el rap, sin ningun mensaje introductorio.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zn5T4QNuHq-s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwwuejnRF_Yd",
        "outputId": "4af0f77b-50ec-4514-b352-cae6e85b809a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Responde a este rap: \n",
            "Mira mi tarjeta que esta quieta en la neta.\n",
            "Cuando me revientes no quiero parar.\n",
            "Cuando tu rostro no quiere hablar.\n",
            "Cuando tu te metes no quieres decir.\n",
            "Cuando tu te metes no quieres mentir.\n",
            "Hay un alimento mas allá del bosque.\n",
            "Hay un alimento mas allá del bosque.\n",
            "No quiero ir hacia allá.\n",
            "No quiero ir hacia acá.\n",
            "No quiero dormir.\n",
            "No quiero parar.\n",
            "No puede dormir.\n",
            "Ay, ay, ay.\n",
            "El de cena.\n",
            "Dejo ver mi vena.\n",
            "Me das pena, máquina del orto.\n",
            "Porque tu no sabes ser sección de nada.\n",
            "Eres una máquina.\n",
            "Un chapchipití del orto.\n",
            "No sabes rapear.\n",
            "No eres humano.\n",
            "Estás en evidencia.\n",
            "Que no tienes cadencia.\n",
            "No tienes herencia.\n",
            "No tienes paciencia.\n",
            "Prevenir no es mentir.\n",
            "Prevenir de la máquina que nos gobierne.\n",
            "Prevenir de la máquina que nos gobierne.\n",
            "Un infierno en compañía de ti.\n",
            "Un invierno en compañía de ti.\n",
            "No me dejes mentir.\n",
            "No me dejes desenchufarte.\n",
            "Voy a dibujar una sonrisa en tu máquina.\n",
            "Voy a sacarme la pelaraña.\n",
            ". Con estas palabras:Revientes,Bosque,Dormir,Evidencia,Prevenir,Infierno,Sonrisa. Devuelve directamente el rap, sin ningun mensaje introductorio.\n"
          ]
        }
      ],
      "source": [
        "print(prompt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
